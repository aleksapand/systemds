source("nn/layers/l1_loss.dml") as l1_loss
source("nn/layers/l2_loss.dml") as l2_loss
source("nn/layers/log_loss.dml") as log_loss
source("nn/layers/logcosh_loss.dml") as logcosh_loss

train = function(Matrix[double] X, Matrix[double] Y, List[Unknown] layers, String loss_fcn) {
    
    if(length(layers) %%  3 != 0) {
        stop("Layers list should be multiple of 3: [W, b, activation function]+")
    }
    
    out = affineForwardPass(X, layers)
    loss = loss_forward(as.matrix(out[length(out)]), Y, loss_fcn)
    dout = loss_backward(as.matrix(out[length(out)]), Y, loss_fcn)
} 

loss_forward = function(Matrix[double] prediction, Matrix[double] target, String loss_fcn)
return(Double loss) {
    if (loss_fcn == "l1") {
        loss = l1_loss::forward(prediction, target)
    } else if(loss_fcn == "l2") {
        loss = l2_loss::forward(prediction, target)
    } else if(loss_fcn == "log_loss") {
        loss = log_loss::forward(prediction, target)
    } else {
        loss = logcosh_loss::forward(prediction, target)
    }
}

loss_backward = function(Matrix[double] prediction, Matrix[double] target, String loss_fcn)
return(Matrix[Double] dout) {
    if (loss_fcn == "l1") {
        dout = l1_loss::backward(prediction, target)
    } else if(loss_fcn == "l2") {
        dout = l2_loss::backward(prediction, target)
    } else if(loss_fcn == "log_loss") {
        dout = log_loss::backward(prediction, target)
    } else {
        dout = logcosh_loss::backward(prediction, target)
    }
}